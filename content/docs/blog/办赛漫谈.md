---
weight: 2
title: 办赛漫谈：从 CTFd 到 H3CTF
---

# 办赛漫谈：从 CTFd 到 H3CTF


### 2020 · 五一欢乐赛

笔者还记得 2020 年的春天，那是最终都没有开学的一个学期。笔者第一次办赛，找来了 Lilac 的几位队员出了些题，就开始到处宣传，把哈工大的新生和外校的朋友们都拉来参赛。当时我们只有 CTFd 可以用，而 CTFd 是不支持动态靶机的。笔者的解决方案是用 docker compose 给一道题目开多个实例：

```yaml
# docker-compose --compatibility up -d --build --scale app=4
version: "3.1"

services:
  app:
    build: ./deploy
    restart: always
    ports:
      - "10111-10114:8000"
    deploy:
      resources:
        limits:
          cpus: '0.20'
          memory: 200M
```

每道题至少有 4 个环境，选手可以自己挑其中一个；当选手的题目环境被打崩，我们管理员就去帮他重置环境。这个破破烂烂的方案竟然支撑着比赛直到结束，也给了我们第一个教训：**一定要自动化实现容器管理**。

### 2023 · Lilac Train

2023 年，笔者实现了 Blueberry 平台。它是训练/赛事两用平台，最早是用于 Lilac 训练和一门课程实验。有趣的是，它的大部分问题都暴露在课程实验中。举几个有代表性的例子：

> **故障记录 20230611-1：io_setup() failed**  
> 33 个参赛者。腾讯云服务器公网部署，4 核 32G 实例。事发时，场上共有 63 个题目容器。  
> SQL 注入题，启动 mysql 时报错： InnoDB: io_setup() failed with EAGAIN after 5 attempts.  
> 按 InnoDB: io_setup() failed 关键字查阅资料，得知 Linux 的 async io 有并发数限制。默认限制是 65536，当前 aio 并发数是 63864，确实临近上限。  
> 修改 aio 并发上限： sysctl -w fs.aio-max-nr=1048576，问题解决。

> **故障记录 20230611-3：硬盘不足**  
> 观察到文件系统爆满。扩容解决。  
> 事后发现，靶机管理器删除容器时，并未删除与之关联的 volume；而有些靶机即使出题人自己没有引入 volume，也会创建 volume，例如 [MySQL 官方镜像](https://github.com/docker-library/mysql/blob/master/8.4/Dockerfile.oracle#L117)。



我们从中学到的教训是：**早点上高强度的生产环境来暴露问题**。


### 2025 · H3CTF

这是 Cranberry 的原型版本支撑的第一场竞赛。由于时间仓促，它使用的实际上是 Blueberry 内核——照抄了 checker、题目管理、任务管理和计分逻辑，甚至还复用了 Blueberry 的靶机管理器。这场竞赛有几个统计数据值得一看：

- 44 道题目
- 171 位参赛者
- 共计启动了 2837 次靶机
- 有 1480200 次 flag 提交（本次比赛有压测题），其中 2119 次成功


H3CTF 整体来说很圆满，但靶机管理器也出过两次 bug。这次学到的教训主要是代码层面的，例如不要过于相信 PostgreSQL 的 JSONB 相关优化器、要加锁防止 checkflag 条件竞争等。
